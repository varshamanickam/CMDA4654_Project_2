---
title: "Multinomial Regression"
author: "Chris Ryan, Jeb Brown, Varsha Manickam, Meghna Kommoju, Zhennan Shen"
date: "2025-04-15"
fontsize: 9pt
classoption: "aspectratio=169"
output: 
  beamer_presentation: 
    fonttheme: professionalfonts
    highlight: kate
    theme: Rochester
header-includes:
- \definecolor{VTmaroon}{HTML}{861F41}
- \usecolortheme[named=VTmaroon]{structure}
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(echo = FALSE,
                      comment = NA,
                      warning = FALSE,
                      message = FALSE)

def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  paste0("\n \\", "footnotesize","\n\n", x, "\n\n \\normalsize")
})


```

## Multinomial Regression

Multinomial Regression (also called Multinomial Logistic Regression) is a classification method that is used to predict nominal outcome variables that have more than two outcomes (polytomous) that do not have a rank or order.
Examples of this would be:

- Classifying flower species (setosa, virginica, veritosa)
- Classifying student programs (academic, vocation, general)
- Classifying student majors (engineering, business, science)

## Assumptions for Multinomial Regression

-   Independence of observations
-   Categories of the outcome variable must be mutually exclusive and exhaustive
-   No multicollinearity between independent variables
-   Linear relationship between continuous variables and the logit transformation of the outcome variable

## Multinomial Regression Basics

-   An extension of Logistic Regression
-   Uses separate Logistic Regression models for each pair of response categories
-   Say there are K Response categories. We choose 1 base or "reference" level and then create K-1 difference Logistic Regression Models comparing
-   Each of these models will model the log-odds that an observation that an observation is in a given category vs the reference category
- The reference category can be any of the categories mathematically and you will get the same results. But it can strategically be picked for better interpretability.

## Multinomial Regression Interpretation

- A Multinomial Regression model with K response categories and P explanatory variables is a collection of K-1 Logistic Regression Models:
  - $log(\pi_2/\pi_1) = \beta_{2,0} + \beta_{2,1}*X_1 + ... + \beta_{2,p}*X_p = X^T\beta_2$
  - $log(\pi_3/\pi_1) = \beta_{3,0} + \beta_{3,1}*X_1 + ... + \beta_{3,p}*X_p = X^T\beta_3$
  - ...
  - $log(\pi_K/\pi_1) = \beta_{K,0} + \beta_{K,1}*X_1 + ... + \beta_{K,p}*X_p = X^T\beta_K$
- Where $\pi_i$ is the probability that a given observation is in category i and category 1 is our reference category.
- The odds that a given observation is in category i vs category 1 is given by $exp(\beta_{2,0} + \beta_{2,1}*X_1 + ... + \beta_{2,p}*X_p)$.
- Since $\sum_{j=1}^{K}\pi_j = 1$, $\pi_i = \pi_i/(\sum_{j=1}^{K}\pi_j) = (\pi_i/\pi_1)/(\sum_{j=1}^{K}\pi_j/\pi_1) = exp(X^T\beta_i)/(1+\sum_{j=2}^{K}exp(X^T\beta_j))$.
- Or if i = 1, $\pi_i = (\pi_1/\pi_1)/(1+\sum_{j=2}^{K}exp(X^T\beta_j)) = 1/(1+\sum_{j=2}^{K}exp(X^T\beta_j))$

## Interpretation of Parameter Estimates

- Let $\beta_{i,j}$ be the parameter corresponding the the coefficient of $X_j$ in the ith logistic regression model.
- a unit increase in $X_j$ results in a total increase in the log-odds by $\beta_{i,j}$. (If all other explanatory variables are kept constant)
- Similar to Logistic Regression, it is easier to interpret odds than log odds.
- For a unit increase in $X_j$, the odds that a given observation is category i vs our reference category changes by a factor of $exp(\beta_{i,j})$.




## Small example

## Multiomial Regression in R
```{r}
 # Loading necessary libraries and the dataset
 library(nnet)
 library(caret)
 library(readr)
 library(dplyr)
 
 steel_faults <- read_csv("steel_faults.csv")
 
 # We need to combine the various fault columns into one column, and get rid of the separate columns
 steel_faults <- steel_faults %>%
   mutate(Fault_Type = case_when(
     Pastry == 1 ~ "Pastry",
     Z_Scratch == 1 ~ "Z_Scratch",
     K_Scatch == 1 ~ "K_Scatch",
     Stains == 1 ~ "Stains",
     Dirtiness == 1 ~ "Dirtiness",
     Bumps == 1 ~ "Bumps",
     Other_Faults == 1 ~ "Other"
   )) %>%
   select(-Pastry, -Z_Scratch, -K_Scatch, -Stains, -Dirtiness, -Bumps, -Other_Faults)
 
 
 # We need to convert the targets to factors since we are dealing with categories
 steel_faults$Fault_Type <- as.factor(steel_faults$Fault_Type)
 
```
 The data we are using for our main example is a dataset that contains various physical and visual measurements of steel plates. These measurements are then used to classify the fault that has occurred in the manufacturing of each plate. 
 
 The types of faults that we will be classifying are:
 
 - Pastry
 - Z Scratch
 - K Scratch
 - Stains
 - Dirtiness
 - Bumps
 - Other Faults
 
 The data was found at https://archive.ics.uci.edu/dataset/198/steel+plates+faults. In our example our goal will to be to build a multinomial regression model that can accurately classify the types of faults that the plates in the dataset have.
 
## Descriptive Statistics
 
Our dataset contains 27 different predictor variables that describe the features of the fault such as size, placement, and luminosity of the faults, and other information such as the type and thickness of the steel that the plate is made of.

Here we can see the distribution of the types of faults in our dataset. 
```{r}
 table(steel_faults$Fault_Type)
```
We have a total of 1940 observations of steel plate faults in our dataset.
 
## Finding Which Predictors to Use

```{r}
# Predictor variable correlation matrix
correlations <- cor(steel_faults %>% select_if(is.numeric))
 
# Predictor variable correlation plot
library(corrplot)
corrplot(correlations, method = "circle")
```

## Building the full model
 
```{r, results='hide'}
# Fitting the multinomial model to the data
model <- multinom(Fault_Type ~ ., data = steel_faults)
 
# Find predicted values that the model suggests
predicted <- predict(model, newdata = steel_faults)
 
summary(model)
```

## Confusion Matrix and Interpretations
```{r}
# Confusion matrix
cm <- confusionMatrix(predicted, steel_faults$Fault_Type)
cm$table

 
cm$byClass
```

